from flask import Flask, request, jsonify, send_from_directory
import os
import json
import logging
from google import genai
from google.genai import types
from datetime import datetime, timedelta
from config import config

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Load configuration
config_name = os.environ.get('FLASK_CONFIG', 'default')
app.config.from_object(config[config_name])

# Configuration variables
MEMORY_FILE = app.config['MEMORY_FILE']
HISTORY_FILE = app.config['HISTORY_FILE']
API_KEY = app.config['GOOGLE_API_KEY']

# Doctors database
DOCTORS_DATA = {
    'cardiology': [
        {'id': 1, 'name': 'Ø¯. Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯', 'rating': 4.8, 'experience': 15, 'price': 300, 'availability': 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…', 'specialties': ['Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨', 'Ù‚Ø³Ø·Ø±Ø© Ø§Ù„Ù‚Ù„Ø¨', 'Ø¬Ø±Ø§Ø­Ø© Ø§Ù„Ù‚Ù„Ø¨']},
        {'id': 2, 'name': 'Ø¯. ÙØ§Ø·Ù…Ø© Ø¹Ù„ÙŠ', 'rating': 4.9, 'experience': 12, 'price': 350, 'availability': 'Ù…ØªØ§Ø­ ØºØ¯Ø§Ù‹', 'specialties': ['Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨', 'Ø¶ØºØ· Ø§Ù„Ø¯Ù…', 'Ø¹Ø¯Ù… Ø§Ù†ØªØ¸Ø§Ù… Ø¶Ø±Ø¨Ø§Øª Ø§Ù„Ù‚Ù„Ø¨']},
        {'id': 3, 'name': 'Ø¯. Ù…Ø­Ù…Ø¯ Ø­Ø³Ù†', 'rating': 4.7, 'experience': 18, 'price': 400, 'availability': 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…', 'specialties': ['Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨', 'Ù‚ØµÙˆØ± Ø§Ù„Ù‚Ù„Ø¨', 'Ø§Ù„Ø°Ø¨Ø­Ø© Ø§Ù„ØµØ¯Ø±ÙŠØ©']}
    ],
    'neurology': [
        {'id': 4, 'name': 'Ø¯. Ø³Ø§Ø±Ø© Ø£Ø­Ù…Ø¯', 'rating': 4.9, 'experience': 20, 'price': 450, 'availability': 'Ù…ØªØ§Ø­ ØºØ¯Ø§Ù‹', 'specialties': ['Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø£Ø¹ØµØ§Ø¨', 'Ø§Ù„ØµØ±Ø¹', 'Ø§Ù„ØµØ¯Ø§Ø¹ Ø§Ù„Ù†ØµÙÙŠ']},
        {'id': 5, 'name': 'Ø¯. Ø¹Ù…Ø± Ù…Ø­Ù…ÙˆØ¯', 'rating': 4.6, 'experience': 14, 'price': 380, 'availability': 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…', 'specialties': ['Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø£Ø¹ØµØ§Ø¨', 'Ø§Ù„Ø³ÙƒØªØ© Ø§Ù„Ø¯Ù…Ø§ØºÙŠØ©', 'Ø§Ù„Ø²Ù‡Ø§ÙŠÙ…Ø±']}
    ],
    'orthopedics': [
        {'id': 6, 'name': 'Ø¯. Ù„ÙŠÙ„Ù‰ Ø­Ø³Ø§Ù…', 'rating': 4.8, 'experience': 16, 'price': 320, 'availability': 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…', 'specialties': ['Ø§Ù„Ø¹Ø¸Ø§Ù…', 'Ø¥ØµØ§Ø¨Ø§Øª Ø§Ù„Ù…Ù„Ø§Ø¹Ø¨', 'Ø¬Ø±Ø§Ø­Ø© Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ']},
        {'id': 7, 'name': 'Ø¯. ÙƒØ±ÙŠÙ… ÙØ¤Ø§Ø¯', 'rating': 4.7, 'experience': 11, 'price': 280, 'availability': 'Ù…ØªØ§Ø­ ØºØ¯Ø§Ù‹', 'specialties': ['Ø§Ù„Ø¹Ø¸Ø§Ù…', 'ÙƒØ³ÙˆØ± Ø§Ù„Ø¹Ø¸Ø§Ù…', 'Ø§Ù„ØªÙ‡Ø§Ø¨ Ø§Ù„Ù…ÙØ§ØµÙ„']}
    ],
    'dermatology': [
        {'id': 8, 'name': 'Ø¯. Ù†ÙˆØ± Ø§Ù„Ù‡Ø¯Ù‰', 'rating': 4.9, 'experience': 13, 'price': 250, 'availability': 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…', 'specialties': ['Ø§Ù„Ø¬Ù„Ø¯ÙŠØ©', 'Ø§Ù„Ø£ÙƒØ²ÙŠÙ…Ø§', 'Ø­Ø¨ Ø§Ù„Ø´Ø¨Ø§Ø¨']},
        {'id': 9, 'name': 'Ø¯. Ø­Ø³Ø§Ù… Ø§Ù„Ø¯ÙŠÙ†', 'rating': 4.5, 'experience': 9, 'price': 220, 'availability': 'Ù…ØªØ§Ø­ ØºØ¯Ø§Ù‹', 'specialties': ['Ø§Ù„Ø¬Ù„Ø¯ÙŠØ©', 'Ø§Ù„ØµØ¯ÙÙŠØ©', 'Ø§Ù„ÙØ·Ø±ÙŠØ§Øª']}
    ],
    'pediatrics': [
        {'id': 10, 'name': 'Ø¯. Ù…Ù†Ù‰ Ø³Ø§Ù„Ù…', 'rating': 4.8, 'experience': 17, 'price': 200, 'availability': 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…', 'specialties': ['Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„', 'Ø§Ù„ØªØ·Ø¹ÙŠÙ…Ø§Øª', 'Ù†Ù…Ùˆ Ø§Ù„Ø£Ø·ÙØ§Ù„']},
        {'id': 11, 'name': 'Ø¯. ÙŠÙˆØ³Ù Ø¹Ø§Ø¯Ù„', 'rating': 4.6, 'experience': 8, 'price': 180, 'availability': 'Ù…ØªØ§Ø­ ØºØ¯Ø§Ù‹', 'specialties': ['Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„', 'Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„ØªÙ†ÙØ³ÙŠ', 'Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©']}
    ],
    'general': [
        {'id': 12, 'name': 'Ø¯. Ø±Ø§Ù†ÙŠØ§ Ø·Ø§Ø±Ù‚', 'rating': 4.7, 'experience': 10, 'price': 150, 'availability': 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…', 'specialties': ['Ø·Ø¨ Ø¹Ø§Ù…', 'Ø§Ù„ÙØ­Øµ Ø§Ù„Ø´Ø§Ù…Ù„', 'Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù…Ø²Ù…Ù†Ø©']},
        {'id': 13, 'name': 'Ø¯. Ø®Ø§Ù„Ø¯ Ù†Ø¨ÙŠÙ„', 'rating': 4.4, 'experience': 7, 'price': 120, 'availability': 'Ù…ØªØ§Ø­ ØºØ¯Ø§Ù‹', 'specialties': ['Ø·Ø¨ Ø¹Ø§Ù…', 'Ø§Ù„Ø³ÙƒØ±ÙŠ', 'Ø¶ØºØ· Ø§Ù„Ø¯Ù…']}
    ],
    'gastroenterology': [
        {'id': 14, 'name': 'Ø¯. Ù‡Ø§Ù„Ø© Ù…Ø­Ù…Ø¯', 'rating': 4.8, 'experience': 14, 'price': 350, 'availability': 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…', 'specialties': ['Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ', 'Ø§Ù„Ù‚ÙˆÙ„ÙˆÙ†', 'Ù‚Ø±Ø­Ø© Ø§Ù„Ù…Ø¹Ø¯Ø©']},
        {'id': 15, 'name': 'Ø¯. Ø·Ø§Ø±Ù‚ Ø³Ø¹Ø¯', 'rating': 4.6, 'experience': 12, 'price': 300, 'availability': 'Ù…ØªØ§Ø­ ØºØ¯Ø§Ù‹', 'specialties': ['Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ', 'Ø§Ù„ÙƒØ¨Ø¯', 'Ø§Ù„Ù…Ø±Ø§Ø±Ø©']}
    ],
    'psychiatry': [
        {'id': 16, 'name': 'Ø¯. ÙŠØ§Ø³Ù…ÙŠÙ† Ø£Ø­Ù…Ø¯', 'rating': 4.9, 'experience': 15, 'price': 400, 'availability': 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…', 'specialties': ['Ø§Ù„Ø·Ø¨ Ø§Ù„Ù†ÙØ³ÙŠ', 'Ø§Ù„Ø§ÙƒØªØ¦Ø§Ø¨', 'Ø§Ù„Ù‚Ù„Ù‚']},
        {'id': 17, 'name': 'Ø¯. Ù…Ø­Ù…ÙˆØ¯ Ø¹Ù„ÙŠ', 'rating': 4.7, 'experience': 18, 'price': 450, 'availability': 'Ù…ØªØ§Ø­ ØºØ¯Ø§Ù‹', 'specialties': ['Ø§Ù„Ø·Ø¨ Ø§Ù„Ù†ÙØ³ÙŠ', 'Ø§Ø¶Ø·Ø±Ø§Ø¨Ø§Øª Ø§Ù„Ù†ÙˆÙ…', 'Ø§Ù„ÙˆØ³ÙˆØ§Ø³ Ø§Ù„Ù‚Ù‡Ø±ÙŠ']}
    ]
}

# Symptom to specialty mapping
SYMPTOM_SPECIALTY_MAP = {
    'ØµØ¯Ø§Ø¹': ['neurology', 'general'],
    'Ø¯ÙˆØ®Ø©': ['neurology', 'cardiology', 'general'],
    'Ø£Ù„Ù… ØµØ¯Ø±': ['cardiology', 'general'],
    'Ø®ÙÙ‚Ø§Ù†': ['cardiology', 'general'],
    'Ø¶ÙŠÙ‚ ØªÙ†ÙØ³': ['cardiology', 'general'],
    'Ø£Ù„Ù… Ø¨Ø·Ù†': ['gastroenterology', 'general'],
    'ØºØ«ÙŠØ§Ù†': ['gastroenterology', 'general'],
    'Ø¥Ø³Ù‡Ø§Ù„': ['gastroenterology', 'general'],
    'Ø¥Ù…Ø³Ø§Ùƒ': ['gastroenterology', 'general'],
    'Ø£Ù„Ù… Ø¸Ù‡Ø±': ['orthopedics', 'general'],
    'Ø£Ù„Ù… Ù…ÙØ§ØµÙ„': ['orthopedics', 'general'],
    'Ø·ÙØ­ Ø¬Ù„Ø¯ÙŠ': ['dermatology', 'general'],
    'Ø­ÙƒØ©': ['dermatology', 'general'],
    'Ø­Ù…Ù‰': ['general', 'pediatrics'],
    'Ø³Ø¹Ø§Ù„': ['general', 'pediatrics'],
    'Ù‚Ù„Ù‚': ['psychiatry', 'general'],
    'Ø§ÙƒØªØ¦Ø§Ø¨': ['psychiatry', 'general'],
    'Ø£Ø±Ù‚': ['psychiatry', 'neurology', 'general'],
    'Ù†Ø³ÙŠØ§Ù†': ['neurology', 'psychiatry', 'general']
}

# Emotional triggers
emotional_triggers = [
    "Ù…Ø±Ø¹ÙˆØ¨", "Ø®Ø§ÙŠÙ", "Ù‚Ù„Ù‚Ø§Ù†", "Ù…ØªÙˆØªØ±", "Ù‡Ù…ÙˆØª", "Ø¨Ø­Ø³ Ø¨Ø¶ÙŠÙ‚", 
    "Ø²Ø¹Ù„Ø§Ù†", "Ø­Ø²ÙŠÙ†", "Ù…Ø®Ù†ÙˆÙ‚", "Ù…Ø¬Ù†ÙˆÙ†", "Ø­Ø§Ø³Ø³ Ø¨Ø¶ÙŠÙ‚"
]

# First aid guides
first_aid_guides = {
    "Ø­Ø±ÙˆÙ‚": "ğŸ”¥ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø±ÙˆÙ‚:\n1. Ø¨Ø¹Ø¯Ù‘ÙŠ Ø§Ù„Ù…ÙŠØ§Ù‡ Ø§Ù„Ø¨Ø§Ø±Ø¯Ø© Ø¹Ù„Ù‰ Ù…ÙƒØ§Ù† Ø§Ù„Ø­Ø±Ù‚ Ù„Ù…Ø¯Ø© 10 Ø¯Ù‚Ø§ÙŠÙ‚.\n2. Ù…ØªØ­Ø·Ø´ Ø«Ù„Ø¬ Ø£Ùˆ Ù…Ø¹Ø¬ÙˆÙ† Ø£Ø³Ù†Ø§Ù†.\n3. Ù„Ùˆ Ø§Ù„Ø­Ø±Ù‚ Ø´Ø¯ÙŠØ¯ Ø£Ùˆ ÙÙŠÙ‡ ÙÙ‚Ø§Ø¹Ø§ØªØŒ Ù„Ø§Ø²Ù… ØªØ±ÙˆØ­ Ø·ÙˆØ§Ø±Ø¦.\n\nâš ï¸ Ø¯Ù‡ Ù…Ø´ ØªØ´Ø®ÙŠØµ Ø·Ø¨ÙŠØŒ Ù„Ùˆ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù…Ø³ØªÙ…Ø±Ø© Ø£Ùˆ Ø²Ø§Ø¯ØªØŒ Ù„Ø§Ø²Ù… ØªØ±ÙˆØ­ Ù„Ø¯ÙƒØªÙˆØ± Ù…ØªØ®ØµØµ.",
    "ØºØ±Ù‚": "ğŸŒŠ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ØºØ±Ù‚:\n1. Ø·Ù„Ø¹ Ø§Ù„Ø´Ø®Øµ Ù…Ù† Ø§Ù„Ù…ÙŠØ© ÙÙˆØ±Ù‹Ø§.\n2. Ù„Ùˆ Ù…Ø´ Ø¨ÙŠØªÙ†ÙØ³ØŒ Ø§Ø¨ØªØ¯ÙŠ **Ø§Ù„Ø¥Ù†Ø¹Ø§Ø´ Ø§Ù„Ù‚Ù„Ø¨ÙŠ Ø§Ù„Ø±Ø¦ÙˆÙŠ (CPR)**.\n3. ÙƒÙ„Ù… Ø§Ù„Ø¥Ø³Ø¹Ø§Ù ÙÙˆØ±Ù‹Ø§.\n\nâš ï¸ Ø¯Ù‡ Ù…Ø´ ØªØ´Ø®ÙŠØµ Ø·Ø¨ÙŠØŒ Ù„Ùˆ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù…Ø³ØªÙ…Ø±Ø© Ø£Ùˆ Ø²Ø§Ø¯ØªØŒ Ù„Ø§Ø²Ù… ØªØ±ÙˆØ­ Ù„Ø¯ÙƒØªÙˆØ± Ù…ØªØ®ØµØµ.",
    "Ø¥ØºÙ…Ø§Ø¡": "ğŸ˜µ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø¥ØºÙ…Ø§Ø¡:\n1. Ù…Ø¯Ø¯ Ø§Ù„Ø´Ø®Øµ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶.\n2. Ø§Ø±ÙØ¹ Ø±Ø¬Ù„Ù‡ Ø´ÙˆÙŠØ©.\n3. Ù„Ùˆ Ù…Ø§ ÙØ§Ù‚Ø´ Ø®Ù„Ø§Ù„ Ø¯Ù‚ÙŠÙ‚Ø©ØŒ Ø§ØªØµÙ„ Ø¨Ø§Ù„Ø¥Ø³Ø¹Ø§Ù.\n\nâš ï¸ Ø¯Ù‡ Ù…Ø´ ØªØ´Ø®ÙŠØµ Ø·Ø¨ÙŠØŒ Ù„Ùˆ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù…Ø³ØªÙ…Ø±Ø© Ø£Ùˆ Ø²Ø§Ø¯ØªØŒ Ù„Ø§Ø²Ù… ØªØ±ÙˆØ­ Ù„Ø¯ÙƒØªÙˆØ± Ù…ØªØ®ØµØµ.",
    "Ø§Ø®ØªÙ†Ø§Ù‚": "ğŸ˜®â€ğŸ’¨ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø®ØªÙ†Ø§Ù‚:\n1. Ø§Ø³Ø£Ù„ Ø§Ù„Ø´Ø®Øµ Ù„Ùˆ ÙŠÙ‚Ø¯Ø± ÙŠØªÙƒÙ„Ù… Ø£Ùˆ ÙŠØ³Ø¹Ù„.\n2. Ù„Ùˆ Ù…Ø´ Ù‚Ø§Ø¯Ø±ØŒ Ø§Ø¨ØªØ¯ÙŠ **Ù…Ù†Ø§ÙˆØ±Ø© Ù‡ÙŠÙ…Ù„ÙŠØ®**.\n3. Ù„Ùˆ ÙÙ‚Ø¯ Ø§Ù„ÙˆØ¹ÙŠØŒ Ø§Ø¨ØªØ¯ÙŠ **Ø§Ù„Ø¥Ù†Ø¹Ø§Ø´ Ø§Ù„Ù‚Ù„Ø¨ÙŠ Ø§Ù„Ø±Ø¦ÙˆÙŠ (CPR)** ÙˆØ§ØªØµÙ„ Ø¨Ø§Ù„Ø¥Ø³Ø¹Ø§Ù.\n\nâš ï¸ Ø¯Ù‡ Ù…Ø´ ØªØ´Ø®ÙŠØµ Ø·Ø¨ÙŠØŒ Ù„Ùˆ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù…Ø³ØªÙ…Ø±Ø© Ø£Ùˆ Ø²Ø§Ø¯ØªØŒ Ù„Ø§Ø²Ù… ØªØ±ÙˆØ­ Ù„Ø¯ÙƒØªÙˆØ± Ù…ØªØ®ØµØµ.",
    "Ø¬Ø±ÙˆØ­": "ğŸ©¸ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ø±ÙˆØ­:\n1. Ù†Ø¸Ù‘Ù Ø§Ù„Ø¬Ø±Ø­ Ø¨Ù…ÙŠØ§Ù‡ Ø¬Ø§Ø±ÙŠØ©.\n2. Ø­Ø· Ø´Ø§Ø´ Ù…Ø¹Ù‚Ù… ÙˆØ§Ø¶ØºØ· Ø¹Ù„ÙŠÙ‡.\n3. Ù„Ùˆ Ø§Ù„Ø¬Ø±Ø­ Ø¹Ù…ÙŠÙ‚ Ø£Ùˆ Ø¨ÙŠÙ†Ø²Ù ÙƒØªÙŠØ±ØŒ Ù„Ø§Ø²Ù… ØªØ±ÙˆØ­ Ø·ÙˆØ§Ø±Ø¦.\n\nâš ï¸ Ø¯Ù‡ Ù…Ø´ ØªØ´Ø®ÙŠØµ Ø·Ø¨ÙŠØŒ Ù„Ùˆ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù…Ø³ØªÙ…Ø±Ø© Ø£Ùˆ Ø²Ø§Ø¯ØªØŒ Ù„Ø§Ø²Ù… ØªØ±ÙˆØ­ Ù„Ø¯ÙƒØªÙˆØ± Ù…ØªØ®ØµØµ.",
    "ØªØ³Ù…Ù…": "â˜ ï¸ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ³Ù…Ù…:\n1. Ù…ØªØ­Ø§ÙˆÙ„Ø´ ØªØ®Ù„ÙŠ Ø§Ù„Ø´Ø®Øµ ÙŠØ±Ø¬Ø¹.\n2. Ø§ØªØµÙ„ Ø¨Ù…Ø±ÙƒØ² Ø§Ù„Ø³Ù…ÙˆÙ… ÙÙˆØ±Ù‹Ø§.\n3. Ø§Ø¹Ø±Ù Ù†ÙˆØ¹ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù„ÙŠ Ø§ØªØ³Ù…Ù… Ù…Ù†Ù‡Ø§ Ù„Ùˆ Ø£Ù…ÙƒÙ†.\n\nâš ï¸ Ø¯Ù‡ Ù…Ø´ ØªØ´Ø®ÙŠØµ Ø·Ø¨ÙŠØŒ Ù„Ùˆ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù…Ø³ØªÙ…Ø±Ø© Ø£Ùˆ Ø²Ø§Ø¯ØªØŒ Ù„Ø§Ø²Ù… ØªØ±ÙˆØ­ Ù„Ø¯ÙƒØªÙˆØ± Ù…ØªØ®ØµØµ.",
    "ØµØ±Ø¹": "âš¡ ÙÙŠ Ø­Ø§Ù„Ø© Ù†ÙˆØ¨Ø© ØµØ±Ø¹:\n1. Ø§Ø¨Ø¹Ø¯ Ø£ÙŠ Ø­Ø§Ø¬Ø© Ù…Ù…ÙƒÙ† ØªØ£Ø°ÙŠÙ‡.\n2. Ù…ØªÙ‚ÙŠØ¯Ù‡ÙˆØ´ØŒ ÙˆØ³ÙŠØ¨Ù‡ Ù„Ø­Ø¯ Ù…Ø§ Ø§Ù„Ù†ÙˆØ¨Ø© ØªØ®Ù„Øµ.\n3. Ù„Ùˆ Ø§Ù„Ù†ÙˆØ¨Ø© Ø§Ø³ØªÙ…Ø±Øª Ø£ÙƒØªØ± Ù…Ù† Ù¥ Ø¯Ù‚Ø§ÙŠÙ‚ØŒ Ø§ØªØµÙ„ Ø¨Ø§Ù„Ø¥Ø³Ø¹Ø§Ù.\n\nâš ï¸ Ø¯Ù‡ Ù…Ø´ ØªØ´Ø®ÙŠØµ Ø·Ø¨ÙŠØŒ Ù„Ùˆ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù…Ø³ØªÙ…Ø±Ø© Ø£Ùˆ Ø²Ø§Ø¯ØªØŒ Ù„Ø§Ø²Ù… ØªØ±ÙˆØ­ Ù„Ø¯ÙƒØªÙˆØ± Ù…ØªØ®ØµØµ.",
    "Ø¶Ø±Ø¨Ø§Øª Ø§Ù„Ø±Ø£Ø³": "ğŸ§  ÙÙŠ Ø­Ø§Ù„Ø© Ø¶Ø±Ø¨Ø© Ø±Ø£Ø³:\n1. Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø´Ø®Øµ Ù„Ùˆ ÙÙŠÙ‡ Ù‚ÙŠØ¡ØŒ ÙÙ‚Ø¯Ø§Ù† ÙˆØ¹ÙŠØŒ Ø£Ùˆ ØµØ¯Ø§Ø¹ Ø´Ø¯ÙŠØ¯.\n2. Ù„Ùˆ ÙÙŠÙ‡ Ø£ÙŠ Ù…Ù† Ø¯ÙˆÙ„ØŒ Ù„Ø§Ø²Ù… ÙŠØ±ÙˆØ­ Ø·ÙˆØ§Ø±Ø¦.\n3. Ù…ØªØ¯ÙŠÙ‡Ø´ Ø£Ø¯ÙˆÙŠØ© Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ´Ø§Ø±Ø© Ø·Ø¨ÙŠØ¨.\n\nâš ï¸ Ø¯Ù‡ Ù…Ø´ ØªØ´Ø®ÙŠØµ Ø·Ø¨ÙŠØŒ Ù„Ùˆ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù…Ø³ØªÙ…Ø±Ø© Ø£Ùˆ Ø²Ø§Ø¯ØªØŒ Ù„Ø§Ø²Ù… ØªØ±ÙˆØ­ Ù„Ø¯ÙƒØªÙˆØ± Ù…ØªØ®ØµØµ.",
    "cpr": "â¤ï¸ Ø¥Ø²Ø§ÙŠ ØªØ¹Ù…Ù„ Ø§Ù„Ø¥Ù†Ø¹Ø§Ø´ Ø§Ù„Ù‚Ù„Ø¨ÙŠ Ø§Ù„Ø±Ø¦ÙˆÙŠ (CPR):\n1. ØªØ£ÙƒØ¯ Ø¥Ù† Ø§Ù„Ù…ÙƒØ§Ù† Ø¢Ù…Ù†ØŒ ÙˆØ§Ù† Ø§Ù„Ø´Ø®Øµ Ù…Ø´ Ø¨ÙŠØªÙ†ÙØ³ Ø£Ùˆ Ù…Ø´ Ø¨ÙŠØ³ØªØ¬ÙŠØ¨.\n2. Ø§Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙˆØ±Ù‹Ø§ (Ø§ØªØµÙ„ Ø¨Ø§Ù„Ø¥Ø³Ø¹Ø§Ù).\n3. Ø­Ø· Ø¥ÙŠØ¯ Ø¹Ù„Ù‰ Ø¥ÙŠØ¯ ÙÙŠ Ù†Øµ ØµØ¯Ø± Ø§Ù„Ø´Ø®Øµ.\n4. Ø§Ø¶ØºØ· Ø¨Ù‚ÙˆØ© ÙˆØ³Ø±Ø¹Ø© (Ø­ÙˆØ§Ù„ÙŠ 100-120 Ø¶ØºØ·Ø© ÙÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©) Ø¨Ø¹Ù…Ù‚ 5-6 Ø³Ù….\n5. Ø¨Ø¹Ø¯ ÙƒÙ„ 30 Ø¶ØºØ·Ø©ØŒ Ù…Ù…ÙƒÙ† ØªØ¹Ù…Ù„ Ù†ÙØ³ÙŠÙ† Ø¥Ù†Ù‚Ø§Ø° Ù„Ùˆ Ù…Ø¯Ø±Ø¨ Ø¹Ù„Ù‰ ÙƒØ¯Ù‡ØŒ Ø£Ùˆ Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø¶ØºØ·Ø§Øª Ø¨Ø³.\n6. Ø§Ø³ØªÙ…Ø± Ù„Ø­Ø¯ Ù…Ø§ ÙŠÙˆØµÙ„ Ø§Ù„Ø¥Ø³Ø¹Ø§Ù Ø£Ùˆ Ø§Ù„Ø´Ø®Øµ ÙŠØ³ØªØ¬ÙŠØ¨.\n\nâš ï¸ Ø¯Ù‡ Ø´Ø±Ø­ Ù…Ø¨Ø³Ø· ÙˆÙ…Ø¨ÙŠØºÙ†ÙŠØ´ Ø¹Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù€ CPR.",
    "Ù…Ù†Ø§ÙˆØ±Ø© Ù‡ÙŠÙ…Ù„ÙŠØ®": "ğŸ‘ Ø¥Ø²Ø§ÙŠ ØªØ¹Ù…Ù„ Ù…Ù†Ø§ÙˆØ±Ø© Ù‡ÙŠÙ…Ù„ÙŠØ® (Ù„Ø´Ø®Øµ ÙˆØ§Ø¹ÙŠ Ø¨ÙŠØ®ØªÙ†Ù‚):\n1. Ø§Ù‚Ù ÙˆØ±Ø§ Ø§Ù„Ø´Ø®ØµØŒ ÙˆØ­Ø§ÙˆØ· ÙˆØ³Ø·Ù‡ Ø¨Ø¥ÙŠØ¯ÙŠÙƒ.\n2. Ø­Ø· Ù‚Ø¨Ø¶Ø© Ø¥ÙŠØ¯Ùƒ ÙÙˆÙ‚ Ø³Ø±Ø© Ø§Ù„Ø´Ø®Øµ Ø¨Ø´ÙˆÙŠØ©ØŒ ÙˆØ¥ÙŠØ¯Ùƒ Ø§Ù„ØªØ§Ù†ÙŠØ© ÙÙˆÙ‚Ù‡Ø§.\n3. Ø§Ø¶ØºØ· Ø¨Ù‚ÙˆØ© ÙˆØ³Ø±Ø¹Ø© Ù„Ù„Ø¯Ø§Ø®Ù„ ÙˆÙ„Ù„Ø£Ø¹Ù„Ù‰ ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚ØªØŒ Ø²ÙŠ Ù…Ø§ ØªÙƒÙˆÙ† Ø¹Ø§ÙŠØ² ØªØ±ÙØ¹ Ø§Ù„Ø´Ø®Øµ.\n4. ÙƒØ±Ø± Ø§Ù„Ø¶ØºØ·Ø§Øª Ø¯ÙŠ Ù„Ø­Ø¯ Ù…Ø§ Ø§Ù„Ø¬Ø³Ù… Ø§Ù„ØºØ±ÙŠØ¨ ÙŠØ·Ù„Ø¹ Ø£Ùˆ Ø§Ù„Ø´Ø®Øµ ÙŠÙÙ‚Ø¯ Ø§Ù„ÙˆØ¹ÙŠ.\n5. Ù„Ùˆ ÙÙ‚Ø¯ Ø§Ù„ÙˆØ¹ÙŠØŒ Ù…Ø¯Ø¯ Ø§Ù„Ø´Ø®Øµ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶ ÙˆØ§Ø¨ØªØ¯ÙŠ CPR.\n\nâš ï¸ Ø¯Ù‡ Ø´Ø±Ø­ Ù…Ø¨Ø³Ø· ÙˆÙ…Ø¨ÙŠØºÙ†ÙŠØ´ Ø¹Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø³Ø¹Ø§ÙØ§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©."
}

def analyze_symptoms(text):
    """Analyze symptoms in text and return relevant specialties"""
    text_lower = text.lower()
    relevant_specialties = set()
    detected_symptoms = []

    for symptom, specialties in SYMPTOM_SPECIALTY_MAP.items():
        if symptom in text_lower:
            detected_symptoms.append(symptom)
            relevant_specialties.update(specialties)

    return list(relevant_specialties), detected_symptoms

def get_doctor_recommendations(specialties, limit=3):
    """Get doctor recommendations based on specialties"""
    recommendations = []

    for specialty in specialties:
        if specialty in DOCTORS_DATA:
            doctors = DOCTORS_DATA[specialty]
            # Sort by rating and availability
            sorted_doctors = sorted(doctors, key=lambda x: (x['rating'], x['availability'] == 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…'), reverse=True)
            recommendations.extend(sorted_doctors[:2])  # Top 2 from each specialty

    # Remove duplicates and limit results
    seen_ids = set()
    unique_recommendations = []
    for doctor in recommendations:
        if doctor['id'] not in seen_ids:
            unique_recommendations.append(doctor)
            seen_ids.add(doctor['id'])

    return unique_recommendations[:limit]

def format_doctor_recommendation(doctors, symptoms):
    """Format doctor recommendations as a response"""
    if not doctors:
        return ""

    response = f"\n\nğŸ‘¨â€âš•ï¸ **Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø£Ø·Ø¨Ø§Ø¡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶:**\n"

    if symptoms:
        response += f"**Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…ÙƒØªØ´ÙØ©:** {', '.join(symptoms)}\n\n"

    for i, doctor in enumerate(doctors, 1):
        availability_icon = "ğŸŸ¢" if doctor['availability'] == 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…' else "ğŸŸ¡"
        response += f"**{i}. {doctor['name']}**\n"
        response += f"   â€¢ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {'â­' * int(doctor['rating'])} ({doctor['rating']})\n"
        response += f"   â€¢ Ø§Ù„Ø®Ø¨Ø±Ø©: {doctor['experience']} Ø³Ù†Ø©\n"
        response += f"   â€¢ Ø§Ù„Ø³Ø¹Ø±: {doctor['price']} Ø¬Ù†ÙŠÙ‡\n"
        response += f"   â€¢ Ø§Ù„ØªÙˆÙØ±: {availability_icon} {doctor['availability']}\n"
        response += f"   â€¢ Ø§Ù„ØªØ®ØµØµØ§Øª: {', '.join(doctor['specialties'][:2])}\n\n"

    response += "ğŸ’¡ **Ù„Ø­Ø¬Ø² Ù…ÙˆØ¹Ø¯:** Ø§Ø°Ù‡Ø¨ Ù„ØµÙØ­Ø© Ø­Ø¬Ø² Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯ ÙˆØ§Ø®ØªØ± Ø§Ù„ØªØ®ØµØµ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨.\n"
    response += "ğŸ”— **Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ø¬Ø²:** [Ø§Ø­Ø¬Ø² Ù…ÙˆØ¹Ø¯Ùƒ Ø§Ù„Ø¢Ù†](appointments.html)"

    return response

def handle_first_aid(text):
    """Check if the text contains first aid keywords and return appropriate guide"""
    text_lower = text.lower()
    for keyword, guide in first_aid_guides.items():
        if keyword in text_lower:
            return guide
    return None

def is_arabic(text):
    """Check if text contains Arabic characters"""
    for ch in text:
        if '\u0600' <= ch <= '\u06FF' or '\u0750' <= ch <= '\u077F':
            return True
    return False

def save_last_question(question):
    """Save the last question to memory file"""
    try:
        with open(MEMORY_FILE, "w", encoding="utf-8") as f:
            json.dump({"last_question": question}, f, ensure_ascii=False)
    except Exception as e:
        logger.error(f"Error saving last question: {e}")

def load_last_question():
    """Load the last question from memory file"""
    try:
        if os.path.exists(MEMORY_FILE):
            with open(MEMORY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("last_question", "")
    except Exception as e:
        logger.error(f"Error loading last question: {e}")
    return ""

def log_conversation(question, answer):
    """Log conversation to history file"""
    try:
        data = []
        if os.path.exists(HISTORY_FILE):
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
        
        data.append({
            "q": question, 
            "a": answer,
            "timestamp": datetime.now().isoformat()
        })
        
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"Error logging conversation: {e}")

def is_emotional(text):
    """Check if text contains emotional triggers"""
    text_lower = text.lower()
    return any(trigger in text_lower for trigger in emotional_triggers)

def get_severity_level(text):
    """Determine severity level of symptoms"""
    text_lower = text.lower()

    # High severity indicators
    high_severity = ['Ø´Ø¯ÙŠØ¯', 'Ù‚ÙˆÙŠ', 'Ù…Ø¤Ù„Ù… Ø¬Ø¯Ø§Ù‹', 'Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹', 'Ø·ÙˆØ§Ø±Ø¦', 'Ù†Ø²ÙŠÙ', 'ÙÙ‚Ø¯Ø§Ù† ÙˆØ¹ÙŠ', 'ØµØ¹ÙˆØ¨Ø© ØªÙ†ÙØ³']
    medium_severity = ['Ù…ØªÙˆØ³Ø·', 'Ù…Ø¤Ù„Ù…', 'Ù…Ø²Ø¹Ø¬', 'ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰', 'ØµØ¹ÙˆØ¨Ø© ÙÙŠ']
    low_severity = ['Ø®ÙÙŠÙ', 'Ø¨Ø³ÙŠØ·', 'Ø£Ø­ÙŠØ§Ù†Ø§Ù‹', 'Ù‚Ù„ÙŠÙ„', 'Ù†Ø§Ø¯Ø±Ø§Ù‹']

    if any(indicator in text_lower for indicator in high_severity):
        return 'high'
    elif any(indicator in text_lower for indicator in medium_severity):
        return 'medium'
    elif any(indicator in text_lower for indicator in low_severity):
        return 'low'
    else:
        return 'medium'  # Default

def get_urgency_message(severity):
    """Get urgency message based on severity"""
    if severity == 'high':
        return "ğŸš¨ **ØªØ­Ø°ÙŠØ±:** Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ ØªØ¨Ø¯Ùˆ Ø´Ø¯ÙŠØ¯Ø©. ÙŠÙÙ†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨ ÙÙˆØ±Ø§Ù‹ Ø£Ùˆ Ø§Ù„Ø°Ù‡Ø§Ø¨ Ù„Ù„Ø·ÙˆØ§Ø±Ø¦."
    elif severity == 'medium':
        return "âš ï¸ **ØªÙ†Ø¨ÙŠÙ‡:** ÙŠÙÙ†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨ ÙÙŠ Ø£Ù‚Ø±Ø¨ ÙˆÙ‚Øª Ù…Ù…ÙƒÙ†."
    else:
        return "ğŸ’¡ **Ù†ØµÙŠØ­Ø©:** ÙŠÙ…ÙƒÙ† Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© Ø£Ùˆ Ù„Ù„Ø§Ø·Ù…Ø¦Ù†Ø§Ù†."

def enhance_ai_prompt(user_input, symptoms, severity):
    """Enhance AI prompt with context"""
    enhanced_prompt = f"""
Ø§Ù„Ù…Ø±ÙŠØ¶ ÙŠØ´ÙƒÙˆ Ù…Ù†: {user_input}

Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {', '.join(symptoms) if symptoms else 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©'}
Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø©: {severity}

ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ…:
1. ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ø¯Ø¦ÙŠ Ù„Ù„Ø£Ø¹Ø±Ø§Ø¶
2. Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ø§Ù„ÙÙˆØ±ÙŠ
3. Ù…ØªÙ‰ ÙŠØ¬Ø¨ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨
4. Ù†ØµØ§Ø¦Ø­ ÙˆÙ‚Ø§Ø¦ÙŠØ©

ØªØ°ÙƒØ±: Ù‡Ø°Ø§ Ù„Ø§ ÙŠØºÙ†ÙŠ Ø¹Ù† Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø®ØªØµ.
"""
    return enhanced_prompt

def filter_medical_question(text):
    """Enhanced medical question filter"""
    text_lower = text.lower()

    # Non-medical keywords
    non_medical_keywords = ["Ø³ÙŠØ§Ø³Ø©", "Ø±ÙŠØ§Ø¶Ø©", "ÙÙŠÙ„Ù…", "Ù…ÙˆØ³ÙŠÙ‚Ù‰", "Ø¨Ø±Ù…Ø¬Ø©", "ØªØ¹Ù„ÙŠÙ…", "ØªØ±ÙÙŠÙ‡", "Ø·Ø¨Ø®", "Ø³ÙØ±"]

    # Medical keywords
    medical_keywords = ["Ø£Ù„Ù…", "ÙˆØ¬Ø¹", "Ù…Ø±Ø¶", "Ø¯ÙˆØ§Ø¡", "Ø·Ø¨ÙŠØ¨", "Ù…Ø³ØªØ´ÙÙ‰", "Ø£Ø¹Ø±Ø§Ø¶", "ØµØ­Ø©", "Ø¹Ù„Ø§Ø¬", "ÙØ­Øµ", "ØªØ­Ù„ÙŠÙ„"]

    # Check for non-medical content
    if any(word in text_lower for word in non_medical_keywords):
        return False

    # Check for medical content
    if any(word in text_lower for word in medical_keywords):
        return True

    # Check for symptoms
    if any(symptom in text_lower for symptom in SYMPTOM_SPECIALTY_MAP.keys()):
        return True

    # Default to medical if uncertain
    return True

def cache_response(user_input, response):
    """Cache responses for better performance"""
    try:
        cache_file = 'response_cache.json'
        cache = {}

        if os.path.exists(cache_file):
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache = json.load(f)

        # Simple hash for caching
        input_hash = str(hash(user_input.lower().strip()))
        cache[input_hash] = {
            'response': response,
            'timestamp': datetime.now().isoformat()
        }

        # Keep only recent entries (last 1000)
        if len(cache) > 1000:
            sorted_cache = sorted(cache.items(), key=lambda x: x[1]['timestamp'], reverse=True)
            cache = dict(sorted_cache[:1000])

        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"Error caching response: {e}")

def get_cached_response(user_input):
    """Get cached response if available"""
    try:
        cache_file = 'response_cache.json'
        if not os.path.exists(cache_file):
            return None

        with open(cache_file, 'r', encoding='utf-8') as f:
            cache = json.load(f)

        input_hash = str(hash(user_input.lower().strip()))
        if input_hash in cache:
            cached_entry = cache[input_hash]
            # Check if cache is not too old (24 hours)
            cached_time = datetime.fromisoformat(cached_entry['timestamp'])
            if datetime.now() - cached_time < timedelta(hours=24):
                return cached_entry['response']

        return None
    except Exception as e:
        logger.error(f"Error getting cached response: {e}")
        return None

def log_analytics(conversation_data):
    """Log detailed analytics for performance monitoring"""
    try:
        analytics_file = 'analytics.json'
        analytics = []

        if os.path.exists(analytics_file):
            with open(analytics_file, 'r', encoding='utf-8') as f:
                analytics = json.load(f)

        analytics.append(conversation_data)

        # Keep only recent entries (last 5000)
        if len(analytics) > 5000:
            analytics = analytics[-5000:]

        with open(analytics_file, 'w', encoding='utf-8') as f:
            json.dump(analytics, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"Error logging analytics: {e}")

def get_analytics_summary():
    """Get analytics summary"""
    try:
        analytics_file = 'analytics.json'
        if not os.path.exists(analytics_file):
            return {}

        with open(analytics_file, 'r', encoding='utf-8') as f:
            analytics = json.load(f)

        # Calculate statistics
        total_conversations = len(analytics)
        symptom_frequency = {}
        severity_distribution = {'high': 0, 'medium': 0, 'low': 0}
        specialty_requests = {}

        for entry in analytics:
            # Count symptoms
            for symptom in entry.get('symptoms', []):
                symptom_frequency[symptom] = symptom_frequency.get(symptom, 0) + 1

            # Count severity
            severity = entry.get('severity', 'medium')
            severity_distribution[severity] = severity_distribution.get(severity, 0) + 1

            # Count specialties
            for specialty in entry.get('specialties', []):
                specialty_requests[specialty] = specialty_requests.get(specialty, 0) + 1

        return {
            'total_conversations': total_conversations,
            'most_common_symptoms': sorted(symptom_frequency.items(), key=lambda x: x[1], reverse=True)[:10],
            'severity_distribution': severity_distribution,
            'most_requested_specialties': sorted(specialty_requests.items(), key=lambda x: x[1], reverse=True)[:10]
        }
    except Exception as e:
        logger.error(f"Error getting analytics summary: {e}")
        return {}

def get_ai_response(user_input, symptoms=None, severity='medium'):
    """Enhanced AI response with context"""
    try:
        # Check cache first
        cached_response = get_cached_response(user_input)
        if cached_response:
            logger.info("Using cached response")
            return cached_response

        client = genai.Client(api_key=API_KEY)
        model = app.config['GOOGLE_MODEL']

        # Enhance prompt with context
        enhanced_input = enhance_ai_prompt(user_input, symptoms or [], severity)

        generate_content_config = types.GenerateContentConfig(
            safety_settings=[
                types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="BLOCK_ONLY_HIGH"),
                types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="BLOCK_ONLY_HIGH"),
                types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_ONLY_HIGH"),
                types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="BLOCK_ONLY_HIGH"),
            ],
            response_mime_type="text/plain",
            system_instruction=[
                types.Part.from_text(text=app.config['SYSTEM_INSTRUCTION']),
            ],
        )

        contents = [
            types.Content(
                role="user",
                parts=[
                    types.Part.from_text(text=enhanced_input),
                ],
            ),
        ]

        response = client.models.generate_content(
            model=model,
            contents=contents,
            config=generate_content_config,
        )

        ai_response = response.text

        # Cache the response
        cache_response(user_input, ai_response)

        return ai_response

    except Exception as e:
        logger.error(f"Error getting AI response: {e}")
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø¯. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."

@app.route('/')
def index():
    """Serve the main HTML page"""
    try:
        with open('diagnosis.html', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return "HTML file not found", 404

@app.route('/favicon.ico')
def favicon():
    """Serve favicon"""
    return send_from_directory('.', 'favicon.svg', mimetype='image/svg+xml')

@app.route('/<path:filename>')
def serve_static(filename):
    """Serve static files"""
    return send_from_directory('.', filename)

@app.route('/chat', methods=['POST'])
def chat():
    """Enhanced chat handler with symptom analysis and doctor recommendations"""
    try:
        data = request.get_json()
        user_message = data.get('message', '').strip()

        if not user_message:
            return jsonify({'error': 'Empty message'}), 400

        # Check if it's a medical question
        if not filter_medical_question(user_message):
            response = "âš ï¸ Ø¹Ø°Ø±Ù‹Ø§ØŒ ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ø³Ø¤Ø§Ù„Ùƒ ØºÙŠØ± Ø·Ø¨ÙŠ. Ø£Ù†Ø§ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø·Ø¨ÙŠØ© ÙˆØ§Ù„ØµØ­ÙŠØ©. ÙŠÙ…ÙƒÙ†Ùƒ Ø³Ø¤Ø§Ù„ÙŠ Ø¹Ù† Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ØŒ Ø§Ù„Ø£Ø¯ÙˆÙŠØ©ØŒ Ø£Ùˆ Ø£ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª ØµØ­ÙŠØ©."
            return jsonify({'response': response})

        # Analyze symptoms and severity
        relevant_specialties, detected_symptoms = analyze_symptoms(user_message)
        severity = get_severity_level(user_message)

        # Check for emotional content
        emotional_response = ""
        if is_emotional(user_message):
            emotional_response = "ğŸ¤— Ø£ÙÙ‡Ù… Ø£Ù†Ùƒ Ù‚Ù„Ù‚Ø§Ù†ØŒ ÙˆÙ‡Ø°Ø§ Ø·Ø¨ÙŠØ¹ÙŠ. Ø¯Ø¹Ù†ÙŠ Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø¨Ø£ÙØ¶Ù„ Ù…Ø§ Ø£Ø³ØªØ·ÙŠØ¹.\n\n"

        # Check for first aid keywords
        first_aid_response = handle_first_aid(user_message)
        if first_aid_response:
            response = emotional_response + first_aid_response
        else:
            # Get enhanced AI response
            ai_response = get_ai_response(user_message, detected_symptoms, severity)
            response = emotional_response + ai_response

            # Add urgency message based on severity
            urgency_message = get_urgency_message(severity)
            response += f"\n\n{urgency_message}"

            # Add doctor recommendations if symptoms detected
            if detected_symptoms and relevant_specialties:
                recommended_doctors = get_doctor_recommendations(relevant_specialties)
                if recommended_doctors:
                    doctor_recommendations = format_doctor_recommendation(recommended_doctors, detected_symptoms)
                    response += doctor_recommendations

        # Save conversation with metadata
        conversation_data = {
            'question': user_message,
            'response': response,
            'symptoms': detected_symptoms,
            'severity': severity,
            'specialties': relevant_specialties,
            'timestamp': datetime.now().isoformat()
        }

        save_last_question(user_message)
        log_conversation(user_message, response)

        # Log detailed analytics
        log_analytics(conversation_data)

        return jsonify({
            'response': response,
            'symptoms': detected_symptoms,
            'severity': severity,
            'recommended_specialties': relevant_specialties
        })

    except Exception as e:
        logger.error(f"Error in chat endpoint: {e}")
        return jsonify({'error': 'Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.'}), 500

@app.route('/history')
def get_history():
    """Get chat history"""
    try:
        if os.path.exists(HISTORY_FILE):
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            return jsonify({'history': data})
        else:
            return jsonify({'history': []})
    except Exception as e:
        logger.error(f"Error getting history: {e}")
        return jsonify({'error': 'Error retrieving history'}), 500

@app.route('/clear-history', methods=['POST'])
def clear_history():
    """Clear chat history"""
    try:
        if os.path.exists(HISTORY_FILE):
            os.remove(HISTORY_FILE)
        if os.path.exists(MEMORY_FILE):
            os.remove(MEMORY_FILE)
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"Error clearing history: {e}")
        return jsonify({'error': 'Error clearing history'}), 500

@app.route('/doctors/<specialty>')
def get_doctors_by_specialty(specialty):
    """Get doctors by specialty"""
    try:
        if specialty not in DOCTORS_DATA:
            return jsonify({'error': 'Specialty not found'}), 404

        doctors = DOCTORS_DATA[specialty]
        return jsonify({'doctors': doctors, 'specialty': specialty})
    except Exception as e:
        logger.error(f"Error getting doctors: {e}")
        return jsonify({'error': 'Error retrieving doctors'}), 500

@app.route('/doctors/recommend', methods=['POST'])
def recommend_doctors():
    """Recommend doctors based on symptoms"""
    try:
        data = request.get_json()
        symptoms_text = data.get('symptoms', '').strip()

        if not symptoms_text:
            return jsonify({'error': 'No symptoms provided'}), 400

        relevant_specialties, detected_symptoms = analyze_symptoms(symptoms_text)
        recommended_doctors = get_doctor_recommendations(relevant_specialties)

        return jsonify({
            'recommended_doctors': recommended_doctors,
            'detected_symptoms': detected_symptoms,
            'relevant_specialties': relevant_specialties
        })
    except Exception as e:
        logger.error(f"Error recommending doctors: {e}")
        return jsonify({'error': 'Error getting recommendations'}), 500

@app.route('/analytics')
def get_analytics():
    """Get system analytics"""
    try:
        summary = get_analytics_summary()
        return jsonify(summary)
    except Exception as e:
        logger.error(f"Error getting analytics: {e}")
        return jsonify({'error': 'Error retrieving analytics'}), 500

@app.route('/health')
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '2.0.0',
        'features': [
            'symptom_analysis',
            'doctor_recommendations',
            'severity_assessment',
            'response_caching',
            'analytics'
        ]
    })

@app.route('/specialties')
def get_specialties():
    """Get all available specialties"""
    try:
        specialties = []
        for specialty, doctors in DOCTORS_DATA.items():
            specialties.append({
                'id': specialty,
                'name': {
                    'cardiology': 'Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨',
                    'neurology': 'Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø£Ø¹ØµØ§Ø¨',
                    'orthopedics': 'Ø§Ù„Ø¹Ø¸Ø§Ù…',
                    'dermatology': 'Ø§Ù„Ø¬Ù„Ø¯ÙŠØ©',
                    'pediatrics': 'Ø·Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„',
                    'general': 'Ø·Ø¨ Ø¹Ø§Ù…',
                    'gastroenterology': 'Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ',
                    'psychiatry': 'Ø§Ù„Ø·Ø¨ Ø§Ù„Ù†ÙØ³ÙŠ'
                }.get(specialty, specialty),
                'doctor_count': len(doctors),
                'available_today': len([d for d in doctors if d['availability'] == 'Ù…ØªØ§Ø­ Ø§Ù„ÙŠÙˆÙ…'])
            })

        return jsonify({'specialties': specialties})
    except Exception as e:
        logger.error(f"Error getting specialties: {e}")
        return jsonify({'error': 'Error retrieving specialties'}), 500

if __name__ == '__main__':
    # Create necessary directories and files
    os.makedirs('static', exist_ok=True)

    # Initialize analytics file if not exists
    if not os.path.exists('analytics.json'):
        with open('analytics.json', 'w', encoding='utf-8') as f:
            json.dump([], f)

    # Initialize cache file if not exists
    if not os.path.exists('response_cache.json'):
        with open('response_cache.json', 'w', encoding='utf-8') as f:
            json.dump({}, f)

    logger.info("ğŸš€ Medical Chatbot Server Starting...")
    logger.info("âœ… Enhanced features enabled:")
    logger.info("   - Symptom Analysis")
    logger.info("   - Doctor Recommendations")
    logger.info("   - Severity Assessment")
    logger.info("   - Response Caching")
    logger.info("   - Analytics Tracking")
    logger.info("   - Performance Monitoring")

    # Run the Flask app
    app.run(debug=True, host='0.0.0.0', port=5000)
